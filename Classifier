# -*- coding: utf-8 -*-
"""Marter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EDpBodF6aEAEHi_UPt0fc6QYHv96pcI-
"""

#Firstly make a binary classification ML
# https://stats.stackexchange.com/questions/484286/training-samples-with-no-labels-to-include-or-not-to-include

#hide
!pip install -Uqq fastbook
import fastbook

#hide
from fastbook import *
from fastai.vision.all import *
from fastai.vision.widgets import *
from fastai.imports import *
from PIL import *

from google.colab import drive
drive.mount('/content/drive')

import zipfile

# !unzip "/content/drive/MyDrive/Colab Notebooks/Marter_data13.zip" -d "/content/drive/MyDrive/Colab Notebooks/"

import pathlib
from pathlib import Path
pathlib.Path.cwd()

Bosmuis = Path("/content/drive/MyDrive/Colab Notebooks/Dataset/Bosmuis")
Egel = Path("/content/drive/MyDrive/Colab Notebooks/Dataset/Egel")
Marter = Path("/content/drive/MyDrive/Colab Notebooks/Dataset/Marter")
Overig = Path("/content/drive/MyDrive/Colab Notebooks/Dataset/Overig")
Spitsmuis = Path("/content/drive/MyDrive/Colab Notebooks/Dataset/Spitsmuis")
Woelmuis = Path("/content/drive/MyDrive/Colab Notebooks/Dataset/Woelmuis")

path = Path("/content/drive/MyDrive/Colab Notebooks/Dataset")

Bosmuis.ls()
Egel.ls()
Marter.ls()
Overig.ls()
Spitsmuis.ls()
Woelmuis.ls()
path.ls()

fns = get_image_files(path)

failed = verify_images(fns)
failed

failed.map(Path.unlink);

for o in path.iterdir():  # iterate over the files in the path
    # convert all PNG, GIF images to RGBA
    f=0
    for o in os.listdir(path/o):
      f+=1
    print(f)

# ImageCleaner(ds, idxs, path)
#https://forums.fast.ai/t/lesson-3-official-topic/67244/427
# https://stackoverflow.com/questions/1233772/pil-does-not-save-transparency

marters = DataBlock( blocks=(ImageBlock, CategoryBlock), 
                    get_items=get_image_files, 
                    splitter=RandomSplitter(valid_pct=0.2, seed=42), #random split in validation/train data
                    get_y=parent_label, #get label based on folder name
                    item_tfms=RandomResizedCrop(128, min_scale=0.5), #what we normally do in practice is to randomly select part of the image, and crop to just that part
                    batch_tfms=aug_transforms(size=224, min_scale=0.75)) #Examples of common data augmentation techniques for images are rotation, flipping, perspective warping, brightness changes and contrast changes. 

dls = marters.dataloaders(path) # We still need to tell fastai the actual source of our data—in this case, the path where the images can be found:

learn = cnn_learner(dls, resnet34, metrics=accuracy, pretrained=True)
learn.fine_tune(2)

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix(figsize=(12,12), dpi=60)

interp.plot_top_losses(30, nrows=30)
#https://stackoverflow.com/questions/68396513/problem-in-lr-find-in-pytorch-fastai-course

learn = cnn_learner(dls, resnet50, metrics=accuracy)
# lr_min,lr_steep = learn.lr_find()
lrs = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))

#We found that these tend to not give the best estimations for a good learning rate, and two other methods were created: the valley algorithm and the slide algorithm. 
# They’re two other methods for getting a much better suggested learning rate to use OOTB without needing any graphical interpretation
print(lrs.minimum)
print(lrs.steep)
print(lrs.valley)
print(f"Minimum/10: {lrs.minimum:.2e}, steepest point: {lrs.steep:.2e}, valley: {lrs.valley:.2e}, slide: {lrs.slide:.2e}") #https://forums.fast.ai/t/new-lr-finder-output/89236/2

learn = cnn_learner(dls, resnet50, metrics=accuracy) # cnn already freezes the model used.
learn.fit_one_cycle(3, 3.63e-03)

learn.unfreeze()

lrs = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))

print(lrs.valley)
print(f"Minimum/10: {lrs.minimum:.2e}, steepest point: {lrs.steep:.2e}, valley: {lrs.valley:.2e}, slide: {lrs.slide:.2e}")

learn.fit_one_cycle(6, lr_max=2.75e-04)

#1e-4 = 0.0001
#5e-4 = 0.0005
#1e-3 = 0.001

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix(figsize=(12,12), dpi=60)

learn = cnn_learner(dls, resnet50, metrics=accuracy) #Create learner
learn.fit_one_cycle(3, 3.63e-03) # fit with automatically frozen version
learn.unfreeze()
learn.fit_one_cycle(2, lr_max=slice(7.59e-07, 1e-04)) # first layer has 1e-6 LR and last layer 1e-4

#fit_one_cycle is different than fit --> starts at low learning rate, increases it gradually increases first 1/3 of batch
#remaining 2/3 decreases.

learn.recorder.plot_loss()

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix(figsize=(12,12), dpi=60)

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_top_losses(4, figsize=(10,11))

#Save en hergebruik een model
learn.save('Marter_resnet50', pickle_protocol=4)
#dls = marters.dataloaders(path) 
# learner=cnn_learner(dls, resnet34, metrics=accuracy)
# learner=learner.load('Marter_resnet34')

learn.export("/content/drive/MyDrive/Colab Notebooks/Marter_herkenner.pkl")
